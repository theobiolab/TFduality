{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append('../../shared/utilsGRF/')\n",
    "from IPython.display import display\n",
    "import networkx as nx\n",
    "import subprocess, glob, re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ku2', 'a4r', 'alpha3', 'kb1', 'alpha2', 'a1', 'ku3', 'a3', 'alpha4r', 'a3r', 'ku4', 'alpha1r', 'alpha3r', 'kb2', 'a2r', 'alpha2r', 'a1r', 'kb3', 'ku1', 'alpha1', 'a2', 'a4', 'kb4', 'alpha4']\n",
      "executing MTT\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "edges=[(1,'a1',2),(2,'a1r',1),(2,'a2',3),(3,'a2r',2),(3,'a3',4),(4,'a3r',3),(4,'a4',1),(1,'a4r',4),\n",
    "       (5,'alpha1',6),(6,'alpha1r',5),(6,'alpha2',7),(7,'alpha2r',6),(7,'alpha3',8),(8,'alpha3r',7),(8,'alpha4',5),(5,'alpha4r',8),\n",
    "      (1,'kb1-x',5),(5,'ku1',1),(2,'kb2-x',6),(6,'ku2',2),(3,'kb3-x',7),(7,'ku3',3),(4,'kb4-x',8),(8,'ku4',4)]\n",
    "\n",
    "nnodes=8\n",
    "MTTfolder='../../shared/utilsGRF' #folder with MTT.py \n",
    "basename='graph'\n",
    "\n",
    "parlist=[x[1] for x in edges]\n",
    "parlist=list(set(parlist))\n",
    "\n",
    "\n",
    "for pnum,par in enumerate(parlist):\n",
    "    if '-x' in par:\n",
    "        parlist[pnum]=parlist[pnum].replace('-x','')\n",
    "print(parlist)\n",
    "\n",
    "graphname=os.path.join(MTTfolder,basename+'.txt')\n",
    "outf=open(graphname,'w')\n",
    "for x in edges:\n",
    "    x_str=list(map(str,x))\n",
    "    outf.write('('+','.join(x_str)+') ')\n",
    "outf.close()\n",
    "\n",
    "#execute_MTT(self):\n",
    "\n",
    "args=[\"python\",os.path.join(MTTfolder,'MTT.py'),graphname]\n",
    "print(\"executing MTT\")\n",
    "print(subprocess.check_call(args))\n",
    "\n",
    "\n",
    "#parse_rhos_from_graphfiles(self):\n",
    "#this was previously called rhos_from_edges\n",
    "edges=np.array(edges)\n",
    "#find files that correspond to the spanning trees\n",
    "files=glob.glob(os.path.join(MTTfolder,basename+'*'))\n",
    "pat=re.compile('[0-9]+.txt')\n",
    "n=0\n",
    "for f in files:\n",
    "    if pat.findall(f):\n",
    "        n+=1\n",
    "all_rhos=[] \n",
    "allGraphs=dict()\n",
    "allterms=dict()\n",
    "for i in range(1,n+1):\n",
    "    fname=os.path.join(MTTfolder,basename+'-%d.txt'%i)\n",
    "\n",
    "    fi=open(fname,'r')\n",
    "    rho_expr='rho_%d='%i\n",
    "    allGraphs[i]=[]\n",
    "    allterms[i]=[]\n",
    "    for lnum,l in enumerate(fi.readlines()):\n",
    "        idxs=np.array(list(map(int,l.strip().split())),dtype=bool)\n",
    "        subset=edges[idxs]\n",
    "        expr=[x[1] for x in subset] #labels that multiply together in a term of the rho\n",
    "        term='*'.join(expr)\n",
    "        if lnum<1:\n",
    "            rho_expr=rho_expr+term\n",
    "        else:\n",
    "            rho_expr=rho_expr+'+'+term\n",
    "        allterms[i].append(term)\n",
    "        #now get Graph\n",
    "        G=nx.DiGraph()\n",
    "        for edge in subset:\n",
    "            n0=int(edge[0])\n",
    "            n1=int(edge[2])\n",
    "            par=edge[1]\n",
    "            G.add_edge(n0,n1,name=par)\n",
    "            G.add_edge\n",
    "        allGraphs[i].append(G)\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "    all_rhos.append(rho_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "kbpat=re.compile(\"kb\")\n",
    "alphapat=re.compile(\"alpha[0-9][^r]\")\n",
    "alpharepat=re.compile(\"alpha[0-9]r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5,6', '50,60'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_1=set([\"1,2\",\"3,4\",\"5,6\"])\n",
    "set_2=set([\"1,2\",\"3,4\",\"50,60\"])\n",
    "set_1.symmetric_difference(set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get mapping between trees rooted at bound state and trees rooted at unbound state:\n",
    "- if there is a binding edge to the root: change for the unbinding edge and that's it\n",
    "- if there is not a binding edge to the root: reverse minimal path. This should result in less alphas in the tree rooted at the unbound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholegraph=nx.DiGraph()\n",
    "for edge in edges:\n",
    "    wholegraph.add_edge(int(edge[0]),int(edge[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the root+term number is an id for the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nnodes=4\n",
    "correspondance=[]\n",
    "for node in range(nnodes+1,nnodes+1+nnodes):\n",
    "    \n",
    "    for n in range(1,nnodes+1): #for trees with n kb edges\n",
    "        \n",
    "        #Gs_b_kb=[] #trees with kb directly to root node\n",
    "        #Gs_b_nokb=[] #trees with no kb directly to root node\n",
    "        Gs_b=[]\n",
    "        IDs=[]\n",
    "        termsb=[]\n",
    "        for t,term in enumerate(allterms[node]):\n",
    "            kbs=kbpat.findall(term)\n",
    "            if len(kbs)==n:\n",
    "                G=allGraphs[node][t]\n",
    "                Gs_b.append(G)\n",
    "                IDs.append(t)\n",
    "                termsb.append(term)\n",
    "                #if \"kb%d-x\"%node in term:\n",
    "                #    Gs_b_kb.append(G)\n",
    "                #else:\n",
    "                #    Gs_b_nokb.append(G)\n",
    "        \n",
    "        #now check that for each of those trees there is a corresponding tree rooted at an unbound node\n",
    "        \n",
    "        \n",
    "        for g,G in enumerate(Gs_b):\n",
    "            \n",
    "            \n",
    "            node_u=node-nnodes\n",
    "            #if True:\n",
    "            for node_u in range(1,nnodes+1):\n",
    "                #look if I have a tree rooted at the unbound that correspond to this graph reversing the minimal path.\n",
    "                #reversing one binding edge only\n",
    "                for t,term in enumerate(allterms[node_u]): \n",
    "                    kbs=kbpat.findall(term)\n",
    "                    if len(kbs)==(n-1): #\n",
    "                    #if True:\n",
    "                        Gu=allGraphs[node_u][t]\n",
    "                        mp=nx.shortest_path(Gu,source=node,target=node_u) #since the tree GU is spanning rooted at node_u, for sure there is a path\n",
    "                        edges_mp=[[mp[i],mp[i+1]] for i in range(len(mp)-1)]\n",
    "\n",
    "                        #get presumably corresponding tree rooted at unbound from the tree rooted at bound\n",
    "                        edgesu=[]\n",
    "                        for edge in G.edges():\n",
    "                            edge_r=[edge[1],edge[0]]\n",
    "                            if not edge_r in edges_mp:\n",
    "                                edgesu.append(\",\".join(map(str,edge)))\n",
    "                            else:\n",
    "                                edgesu.append(\",\".join(map(str,edge_r)))\n",
    "                        edgesu=set(edgesu)\n",
    "                        newedgesu=[\",\".join(map(str,x)) for x in Gu.edges()]\n",
    "\n",
    "                        newedgesu=set(newedgesu)\n",
    "                        if len(edgesu.symmetric_difference(newedgesu))==0:\n",
    "                            nalphasb=len(alphapat.findall(termsb[g]))\n",
    "                            nalphasu=len(alphapat.findall(term))\n",
    "                            if nalphasb-nalphasu>=0:\n",
    "                                correspondance.append([node,n,IDs[g],node_u,t,nalphasb-nalphasu])\n",
    "                            #print(\"Ge\",G.edges())\n",
    "                            #print(\"Gue\",Gu.edges())\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.vstack(correspondance),columns=[\"node\",\"nkb\",\"IDb\",\"node_u\",\"IDu\",\"alphadif\"])\n",
    "df[\"unique_u\"]=[x[0]+\"-\"+x[1] for x in list(zip(df[\"node_u\"].astype(str),df[\"IDu\"].astype(str)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 384, 384, 384, 384, 384, 384, 384]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(allterms[x]) for x in allterms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not  163\n",
      "not  164\n",
      "not  167\n",
      "not  170\n",
      "not  174\n",
      "not  175\n",
      "not  178\n",
      "not  181\n",
      "not  198\n",
      "not  199\n",
      "not  202\n",
      "not  205\n",
      "not  209\n",
      "not  210\n",
      "not  212\n",
      "not  213\n",
      "not  216\n",
      "not  217\n",
      "not  221\n",
      "not  222\n",
      "not  224\n",
      "not  225\n",
      "not  226\n",
      "not  228\n",
      "not  229\n",
      "not  233\n",
      "not  235\n",
      "not  237\n",
      "not  240\n",
      "not  266\n",
      "not  267\n",
      "not  269\n",
      "not  270\n",
      "not  271\n",
      "not  273\n",
      "not  274\n",
      "not  278\n",
      "not  280\n",
      "not  282\n",
      "not  285\n",
      "not  290\n",
      "not  291\n",
      "not  293\n",
      "not  294\n",
      "not  295\n",
      "not  297\n",
      "not  298\n",
      "not  301\n",
      "not  302\n",
      "not  304\n",
      "not  305\n",
      "not  306\n",
      "not  307\n",
      "not  310\n",
      "not  311\n",
      "not  313\n",
      "not  314\n",
      "not  315\n",
      "not  319\n",
      "not  321\n",
      "not  323\n",
      "not  326\n",
      "not  338\n",
      "not  339\n",
      "not  347\n",
      "not  350\n",
      "not  379\n",
      "not  382\n",
      "not  36\n",
      "not  41\n",
      "not  46\n",
      "not  48\n",
      "not  49\n",
      "not  54\n",
      "not  56\n",
      "not  57\n",
      "not  62\n",
      "not  64\n",
      "not  65\n",
      "not  110\n",
      "not  115\n",
      "not  117\n",
      "not  118\n",
      "not  224\n",
      "not  229\n",
      "not  231\n",
      "not  232\n",
      "not  235\n",
      "not  236\n",
      "not  239\n",
      "not  242\n",
      "not  246\n",
      "not  248\n",
      "not  251\n",
      "not  252\n",
      "not  253\n",
      "not  256\n",
      "not  257\n",
      "not  258\n",
      "not  260\n",
      "not  261\n",
      "not  264\n",
      "not  265\n",
      "not  266\n",
      "not  268\n",
      "not  269\n",
      "not  272\n",
      "not  273\n",
      "not  274\n",
      "not  276\n",
      "not  277\n",
      "not  286\n",
      "not  288\n",
      "not  290\n",
      "not  291\n",
      "not  293\n",
      "not  295\n",
      "not  296\n",
      "not  302\n",
      "not  304\n",
      "not  306\n",
      "not  307\n",
      "not  324\n",
      "not  326\n",
      "not  328\n",
      "not  329\n",
      "not  349\n",
      "not  351\n",
      "not  353\n",
      "not  354\n",
      "not  371\n",
      "not  374\n",
      "not  375\n",
      "not  376\n",
      "not  378\n",
      "not  379\n",
      "not  53\n",
      "not  58\n",
      "not  60\n",
      "not  61\n",
      "not  124\n",
      "not  126\n",
      "not  127\n",
      "not  136\n",
      "not  148\n",
      "not  150\n",
      "not  151\n",
      "not  155\n",
      "not  160\n",
      "not  162\n",
      "not  163\n",
      "not  191\n",
      "not  196\n",
      "not  198\n",
      "not  199\n",
      "not  237\n",
      "not  239\n",
      "not  241\n",
      "not  242\n",
      "not  258\n",
      "not  260\n",
      "not  261\n",
      "not  265\n",
      "not  270\n",
      "not  272\n",
      "not  273\n",
      "not  274\n",
      "not  276\n",
      "not  278\n",
      "not  279\n",
      "not  286\n",
      "not  288\n",
      "not  290\n",
      "not  291\n",
      "not  308\n",
      "not  309\n",
      "not  310\n",
      "not  312\n",
      "not  313\n",
      "not  315\n",
      "not  316\n",
      "not  320\n",
      "not  322\n",
      "not  324\n",
      "not  327\n",
      "not  332\n",
      "not  333\n",
      "not  334\n",
      "not  336\n",
      "not  337\n",
      "not  339\n",
      "not  340\n",
      "not  341\n",
      "not  344\n",
      "not  345\n",
      "not  346\n",
      "not  348\n",
      "not  349\n",
      "not  365\n",
      "not  368\n",
      "not  369\n",
      "not  370\n",
      "not  372\n",
      "not  373\n",
      "not  162\n",
      "not  163\n",
      "not  167\n",
      "not  168\n",
      "not  171\n",
      "not  175\n",
      "not  190\n",
      "not  191\n",
      "not  194\n",
      "not  195\n",
      "not  198\n",
      "not  202\n",
      "not  205\n",
      "not  206\n",
      "not  209\n",
      "not  213\n",
      "not  216\n",
      "not  224\n",
      "not  227\n",
      "not  228\n",
      "not  239\n",
      "not  248\n",
      "not  273\n",
      "not  274\n",
      "not  276\n",
      "not  277\n",
      "not  278\n",
      "not  281\n",
      "not  282\n",
      "not  285\n",
      "not  286\n",
      "not  288\n",
      "not  289\n",
      "not  290\n",
      "not  293\n",
      "not  296\n",
      "not  298\n",
      "not  302\n",
      "not  305\n",
      "not  306\n",
      "not  309\n",
      "not  310\n",
      "not  312\n",
      "not  313\n",
      "not  314\n",
      "not  317\n",
      "not  318\n",
      "not  320\n",
      "not  321\n",
      "not  322\n",
      "not  323\n",
      "not  325\n",
      "not  326\n",
      "not  329\n",
      "not  332\n",
      "not  334\n",
      "not  338\n",
      "not  341\n",
      "not  342\n",
      "not  345\n",
      "not  346\n",
      "not  348\n",
      "not  349\n",
      "not  350\n",
      "not  353\n",
      "not  356\n",
      "not  358\n",
      "not  362\n"
     ]
    }
   ],
   "source": [
    "ntree=384\n",
    "for nodeb in range(5,5+nnodes):\n",
    "    subdf=df[df[\"node\"]==nodeb]\n",
    "    ar=subdf[\"IDb\"].values\n",
    "    for i in range(ntree):\n",
    "        if not i in ar:\n",
    "            print(\"not \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for nodeu in range(1,1+nnodes):\n",
    "    subdf=df[df[\"node_u\"]==node_u]\n",
    "    ar=subdf[\"IDu\"].values\n",
    "    for i in range(ntree):\n",
    "        if not i in ar:\n",
    "            print(\"not \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids,counts=np.unique(df[\"unique_u\"],return_counts=True)\n",
    "min(counts),max(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df[\"alphadif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
